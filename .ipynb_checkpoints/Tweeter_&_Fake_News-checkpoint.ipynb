{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/planchon/tweeter_fakenews/blob/main/Tweeter_%26_Fake_News.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WgIMZx7EsiMn"
   },
   "source": [
    "# Tweeter & Fake news\n",
    "Notebook jupyter du projet tweeter et fake news par Arnaud Valette & Paul Planchon\n",
    "\n",
    "run the first cell once to be sure all the librairies are installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /home/paul/.local/lib/python3.9/site-packages (4.1.0)\n",
      "Requirement already satisfied: pandas in /home/paul/.local/lib/python3.9/site-packages (1.3.3)\n",
      "Requirement already satisfied: numpy in /home/paul/.local/lib/python3.9/site-packages (1.21.2)\n",
      "Requirement already satisfied: matplotlib in /home/paul/.local/lib/python3.9/site-packages (3.4.3)\n",
      "Requirement already satisfied: python-dotenv in /home/paul/.local/lib/python3.9/site-packages (0.19.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/paul/.local/lib/python3.9/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/paul/.local/lib/python3.9/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/paul/.local/lib/python3.9/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (8.1.2)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from cycler>=0.10->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/lib/python3/dist-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in /home/paul/.local/lib/python3.9/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /usr/lib/python3/dist-packages (from tweepy) (2.25.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib<2,>=1.0.0->tweepy) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install tweepy pandas numpy matplotlib python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "TQ2HXk2oshYb"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import dotenv_values\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### env vars\n",
    "in a folder `../creds` put an .env file with\n",
    "```\n",
    "API_KEY=\"\"\n",
    "API_SECRET=\"\"\n",
    "API_TOKEN=\"\"\n",
    "```\n",
    "which are the creds from twitter dev portal [twitter portal](https://developer.twitter.com/en/portal/projects/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = dotenv_values(\"../creds/.env\")\n",
    "API_KEY    = env_var[\"API_KEY\"]\n",
    "API_SECRET = env_var[\"API_SECRET\"]\n",
    "API_TOKEN  = env_var[\"API_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.AppAuthHandler(API_KEY, API_SECRET)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monde website data\n",
    "getting the JSON data from [le monde](https://www.lemonde.fr/webservice/decodex/updates) decodex updates feed\n",
    "\n",
    "### categories\n",
    " - 1: Site parodique\n",
    " - 2: Fake news\n",
    " - 3: Faire attention\n",
    " - 4: OK mais il ne faut pas h√©siter a croiser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    decodex_site = pd.read_csv(\"./monde_site.csv\", index_col=0)\n",
    "    with open('monde_urls.pickle', 'rb') as handle:\n",
    "        site_index_to_url = pickle.load(handle)\n",
    "except Exception:\n",
    "    decodex_site = pd.DataFrame(requests.get(\"https://www.lemonde.fr/webservice/decodex/updates\").json()[\"sites\"]).T.drop(3, 1).rename(columns={0: \"categorie\", 1: \"description\", 2: \"site\"})\n",
    "    decodex_url = requests.get(\"https://www.lemonde.fr/webservice/decodex/updates\").json()[\"urls\"] # urls of website, including sometimes twitter data\n",
    "\n",
    "    # convert the url to index dict to an index to url dict\n",
    "    site_index_to_url = {}\n",
    "    for x, y in decodex_url.items():\n",
    "        try:\n",
    "            if site_index_to_url[y]:\n",
    "                site_index_to_url[y].append(x)\n",
    "        except Exception as e:\n",
    "            site_index_to_url[y] = [x]\n",
    "\n",
    "    # we save data to disk\n",
    "    decodex_site.to_csv(\"monde_site.csv\")\n",
    "    with open('monde_urls.pickle', 'wb') as handle:\n",
    "        pickle.dump(site_index_to_url, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1982: 'twitter.com/france_soir',\n",
       " 1981: 'twitter.com/ThierryRegenere',\n",
       " 1980: 'twitter.com/silvano_trotta',\n",
       " 1976: 'twitter.com/emakrusi?lang=fr',\n",
       " 1973: 'twitter.com/llp_le_vrai',\n",
       " 1971: 'twitter.com/covid_infos',\n",
       " 1893: 'twitter.com/Elishean',\n",
       " 1892: 'twitter.com/DrMo7oG',\n",
       " 1891: 'twitter.com/yetiblog',\n",
       " 1751: 'twitter.com/AfriPulse_FR',\n",
       " 1748: 'twitter.com/WhatsupicFr',\n",
       " 1747: 'twitter.com/suavelos_fr',\n",
       " 1726: 'twitter.com/LBDTSS',\n",
       " 1699: 'twitter.com/onaimelafrance',\n",
       " 1649: 'twitter.com/thomasjoly60',\n",
       " 1586: 'twitter.com/EuroScoop_FR',\n",
       " 1526: 'twitter.com/drwakefield',\n",
       " 1508: 'twitter.com/allosante2016',\n",
       " 1479: 'twitter.com/gatewaypundit',\n",
       " 1476: 'twitter.com/alainsoraloffic',\n",
       " 1474: 'twitter.com/david_vanh',\n",
       " 1472: 'twitter.com/prisonplanet',\n",
       " 1469: 'twitter.com/nosmedias_fr',\n",
       " 1467: 'twitter.com/healthranger',\n",
       " 1462: 'twitter.com/delitdimages',\n",
       " 1417: 'twitter.com/wucnews',\n",
       " 1411: 'twitter.com/onsaitceque',\n",
       " 1273: 'twitter.com/AstuceDuJourMag',\n",
       " 1261: 'twitter.com/RealAlexJones',\n",
       " 1254: 'twitter.com/InvestigAction',\n",
       " 1233: 'twitter.com/envie_devivre',\n",
       " 1232: 'twitter.com/RidiculeTV',\n",
       " 1225: 'twitter.com/Europe_Israel',\n",
       " 1221: 'twitter.com/Civilwarineurop',\n",
       " 1218: 'twitter.com/spiritsciences',\n",
       " 1136: 'twitter.com/astucenaturelle',\n",
       " 1135: 'twitter.com/Santeplusmag',\n",
       " 1134: 'twitter.com/jpney',\n",
       " 916: 'twitter.com/tvlofficiel',\n",
       " 912: 'twitter.com/UnleashMind',\n",
       " 905: 'twitter.com/santeici',\n",
       " 875: 'twitter.com/Letribunaldunet',\n",
       " 839: 'twitter.com/beforeitsnews',\n",
       " 829: 'twitter.com/InfoMdia',\n",
       " 826: 'twitter.com/Dreuz_1fo',\n",
       " 821: 'twitter.com/infolibnews',\n",
       " 818: 'twitter.com/YannMerkado',\n",
       " 817: 'twitter.com/WikistrikeW',\n",
       " 814: 'twitter.com/WantedPedo',\n",
       " 807: 'twitter.com/tprincedelamour',\n",
       " 803: 'twitter.com/SwagActu',\n",
       " 792: 'twitter.com/RussiaInsider',\n",
       " 791: 'twitter.com/1RiposteLaique',\n",
       " 786: 'twitter.com/reseau_internat',\n",
       " 782: 'twitter.com/ReinformationRC',\n",
       " 781: 'twitter.com/RedState',\n",
       " 770: 'twitter.com/paris_vox',\n",
       " 769: 'twitter.com/Panamza',\n",
       " 765: 'twitter.com/nord_actu',\n",
       " 763: 'twitter.com/NiceProvenceInf',\n",
       " 752: 'twitter.com/ObservateursCH',\n",
       " 746: 'twitter.com/PrJoyeux',\n",
       " 739: 'twitter.com/LaGaucheMaTuer',\n",
       " 736: 'twitter.com/linsoumis_fr',\n",
       " 735: 'twitter.com/linformatrice',\n",
       " 732: 'twitter.com/pierrejovanovic',\n",
       " 731: 'twitter.com/JeuneNation',\n",
       " 725: 'twitter.com/infosbordeaux',\n",
       " 722: 'twitter.com/infowars',\n",
       " 721: 'twitter.com/infovsinfo',\n",
       " 717: 'twitter.com/David_vanH',\n",
       " 716: 'twitter.com/degage_hollande',\n",
       " 714: 'twitter.com/Herissident',\n",
       " 713: 'twitter.com/HenryMakow',\n",
       " 709: 'twitter.com/guy_fawkes_news',\n",
       " 706: 'twitter.com/EetR_National',\n",
       " 702: 'twitter.com/diktacratie',\n",
       " 701: 'twitter.com/MbalaDieudo',\n",
       " 694: 'twitter.com/davidicke',\n",
       " 693: 'twitter.com/DailyNewsBin',\n",
       " 690: 'twitter.com/corbettreport',\n",
       " 685: 'twitter.com/breizh_info',\n",
       " 683: 'twitter.com/boris_lay',\n",
       " 681: 'twitter.com/@barenakedislam',\n",
       " 678: 'twitter.com/antipresse_net',\n",
       " 673: 'twitter.com/AE911Truth',\n",
       " 670: 'twitter.com/21WIRE',\n",
       " 668: 'twitter.com/LNParadigme'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get alls twitter link from the urls of decodex\n",
    "fake_news_index = list(decodex_site[decodex_site[\"categorie\"] == 2].index)\n",
    "fake_news_twitter = {}\n",
    "\n",
    "for i in fake_news_index:\n",
    "    try:\n",
    "        for url in site_index_to_url[i]:\n",
    "            if \"twitter\" in url:\n",
    "                fake_news_twitter[i] = url\n",
    "    except Exception:\n",
    "        pass\n",
    "            \n",
    "fake_news_twitter"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO8ifUUper3XA3O0xBAGKUW",
   "include_colab_link": true,
   "name": "Tweeter & Fake News",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
